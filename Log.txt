PA2 - Log

General:
For each step, I've created one or two functions to generate the required graphs, as well as a main() function that calls all of these functions in sequence. I've also included several helper functions that automate parts of the data processing, which are listed above the section for Step 1. In regards to absent data, I've chosen to replae all "NA" entries with the mean for that attribute so as not to decrease the amount of available data for calculations. Note that this is done at the beginning of the data preprocessing, and so any further calculations of attribute means will include those original mean values. This shouldn't have an effect on the value, though, as adding the mean of a sequence to the data for that sequence does not change the average value.

Step 1:
To create a frequency diagram for a given attribute, I first strip out that attribute from the total dataset and put it in an array. Then, I create a set out of that array that only holds a single copy of each element and is sorted. This is handled through the helper function "create_unique()". Finally, I create a Frequency array that matches each element in the set with its frequency in the original array. This is handled through the "get_count()" helper function. All of this logic is contained within the "process_data()". After returning this set of unique elements and the array of their respective frequencies, I can plot these values on a bar graph in order to visualize how often different values for the given attribute appear. For example, by running this function on the Cylinders attribute, we can see that the dataset is predominantly 4, 6, and 8 Cylinder engines, with very few of 3 or 5 cylinders, and no instances of 7 cylinders. Likewise, we can run it on the Origin attribute and see that the majority of cars in the dataset have an origin of "1", which corresponds to being made in the US. 

Step 2:
This step requires that we create a Pie chart, which contains almost the exact same data as a frequency diagram, simply represented differently. Because of this, we will follow the same exact data preprocessing steps as in Step 1, making use of the "process_data()" helper function. In fact, these two tasks being so similar is the entire reason I decided to abstract the data preprocessing out into its own function. After again returning a set of unique elements and their corresponding frequencies, we use matplotlib to graph them with a pie chart, which will automatically assign a percentage value to each category. Similar to the frequency diagram, this allows us to see how prominant the different values for a given attribute are, however now instead of comparing them to a linear count, we can compare them to each other. For example, while a frequency diagram tells us that there are somewhere above 200 cars made in the US within the dataset, the pie chart tells us that this comprises 67.6% of the instances. 

Step 3:
The dot chart shows us the spread of attributes with a more continuous range of values, as well as where these values are concentrated. To create this graph, I aggregate all of the instances of this attribute in the dataset, sort them, and then graph them as x values along the line y=1. By graphing them in this way as a scatter plot with the y axis removed, we end up with a plot that lines up all instances of the attribute and gives insight to their range and where they are concentrated. For example, we can see that the MSRP of cars in this dataset are heavily concentrated between 2300 and 5000, but that there are a small amount of instances with MSRPs above 7500, with the max being close to 22500.

Step 4:
This step is essentially two frequency diagrams, with the cutoff points for the bars assigned in different ways. For approach 1, I created half-open intervals corresponding to the ratings on the given table. So, if an instance has an MPG of less than or equal to 13, it is considered in category 1. If it is greater than 13 but less than or equal to 14, it is in category 2. Etc. I use hardcoded if/elif/else statements to get frequency counts for the different rating categories, and then plot them on a bar graph. For approach 2, these cutoffs are created programmatically instead. I first calculate the maximum and minimum values, and then subtract the min from the max to find the range of the data. Then, dividing this range in 5 to get equal bin widths, I create 5 cutoff poins that create 5 categories of this bin size. Finally, just as in approach 1, I iterate through and calculate the frequency for each of these bins, and plot the results on a bar graph.

Step 5:
Step 5 creates a histogram of the given attribute, which matplotlib handles mostly automatically. For processing, I simply gather all of the instances of the given attribute and sort them, then pass it to matplotlib to create a histogram using the default number of bins, 10. This works essentially like approach 2 from step 4, and allows me to visualize which 10% of the range is the data most concentrated in, as well as how it is shaped. For example, we can see that Acceleration is concentrated mostly around 15, with a steady decrease in both directions, while MSRP is heavily concenctrated in the 20% of the range less than 7500, with almost nothing in the greater bins.

Step 6:
Here we create scatter plots that plot several attributes against MPG. We do this by creating an array that holds each instance of the given attribute, as well as one that holds the corresponding MPG value of that instance, and plotting these as points on a scatter plot, with MPG as the y-axis. This shows us generally how the two attributes are related in the shape of the data. For example, we can see that both horsepower and weight are negatively correlated, which means that as horsepower or weight increases, the MPG tends to decrease. Other attributes, such as acceleration, show only a very loose correlation to MPG, which we can tell because the graph appears to be closer to an amorphous blob of points, rather than a general line or trend.

Step 7:
This step asks us to take the graphs generated in Step 6 and overlay them with a Least Squares regression line for linear regression, the formula for which is copied from the course notes. This line allows us to better visualize the relative direction of the relationship between the two attributes, as well as providing a concrete number for how strong this relationship is. For example, as we said before, horsepower and weight are negatively correlated to MPG, and we can see that this relationship is very strong (-0.87 and -0.78, respectively.) We can also see that, as we said before, the relationship between acceleration and MPG is very weak, with a correlation coefficient of only 0.41, although it is interesting to note that this is a positive relationship instead of negative as the first two were. It also asks us to make one special graph that compares displacement to weight instead of MPG. From this graph, we see that displacement and weight are very strongly positively correlated, with a correlation coefficient of 0.93.

Step 8:
This step uses box plots to calculate the range of the MPG attribute for each of the values of Model Year, as well as providing information about where each quartile and median is for the given year, and whether there are any outliers. This is done by creating a dictionary with the keys being each given model year, and the value associated to a given model year being an array of MPG values for each instance with the given Modeel Year. We then calculate a box plot, which has several features. Firstly, any outliers are listed as unconnected points above or below the main box for a given year. The extent of the upper and lower "arms" of the box denote the full range, with the top arm encompassing the upper 25% of the data and the bottom arm covering the lower 25%. The middle 50% range is contained within the box itself, with the orange line within the box marking the median for that year. For example, we can see that cars made in '78, despite having a large range of MPG values between ~16-39, or ~16-44 if you include the outlier, we can see that 50% of the data lies between 19-26, which is a much smaller range, and the median of the dataset is ~21.

Step 9:
This graph is a multiple frequencies graph of the frequency for Model Years, broken up by the car's origin. So, by processing this data in a very similar way to the initial box plots but splitting the data into different arrays based on origin, we can not only compare the frequency of Model Years for each origin on its own, but also for each Model Year we can compare the distribution of car origins. For example, we can see initially that cars made in the US are much more prevelant in this dataset than those made in Europe or Japan. We also see that '73 was the most common year for cars made in the US, but '76 was the most common for cars made in Europe, and '78 for cars made in Japan. Finally, we can see that although there are far more European cars in the dataset made in '70 and in '76, Europe and Japan are about equal during '72, and Japan produced more cars from this dataset in '77 and '78. 


Bonus Step:
For the bonus, I created a Stem plot that plots the average MPG value for each Model Year, and compares them to a baseline that is the average MPG value for all cars in the dataset. In this graph, the red horizontal line running through the center is the baseline and represents the average MPG value for the entire dataset, which comes out to 21.1. Then, we have the average for each year plotted as a separate point either above or below this baseline, giving us insight to how the average MPG of cars changed over time as well as how it compares to the total average as represented by this dataset. We see that, in general, cars before '74 fell below this baseline average, while later models had better MPG, and in general the average MPG tends to increase as time goes on. To create this graph, I set up an array of averages that contains 10 entries, one for each model year from '70-'79. I then iterate through the dataset and calculate the average for instances of each model year, as well as one big average for the entire dataset. Matplotlib then allows me to plot these yearly averages as points, as if on a scatter plot, as well as plotting a separate baseline of y=(total average MPG). It automatically creates stems from each datapoint to the baseline, allowing you to easily see how the data is shaped compared to this aggregate average.